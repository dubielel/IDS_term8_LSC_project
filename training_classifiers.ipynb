{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9e3fe966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import CheckpointConfig, RunConfig\n",
    "from ray.air.integrations.wandb import WandbLoggerCallback\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.util.joblib import register_ray\n",
    "\n",
    "import optuna\n",
    "\n",
    "import wandb\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    balanced_accuracy_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57369154",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_RUNNING_LOCALLY = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_RUNNING_LOCALLY:\n",
    "    DATASET_PATH = './BindingDB_cleaned_with_mols_&_fingerprints_&_embeddings_LOCAL.pkl'\n",
    "else:\n",
    "    DATASET_PATH = './BindingDB_cleaned_with_mols_&_fingerprints_&_embeddings.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "905176f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERACTION_THRESHOLD = 1.8 if IS_RUNNING_LOCALLY else 10\n",
    "FINGERPRINT_SIZE = 256\n",
    "\n",
    "HYPERPARAMETER_TUNING_DATASET_SIZE = 0.1\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "VALID_SIZE = 0.2\n",
    "SEED = 42\n",
    "\n",
    "N_SPLITS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7255863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 2691981 to 38516\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Monomer ID           1000 non-null   float64\n",
      " 1   Target ID            1000 non-null   float64\n",
      " 2   Target type          1000 non-null   object \n",
      " 3   Ki (nM)              1000 non-null   float64\n",
      " 4   Drug SMILES          1000 non-null   object \n",
      " 5   Target Sequence      1000 non-null   object \n",
      " 6   Mols                 1000 non-null   object \n",
      " 7   ECPF                 1000 non-null   object \n",
      " 8   Topological Torsion  1000 non-null   object \n",
      " 9   Protein Embedding    1000 non-null   object \n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 85.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(DATASET_PATH)\n",
    "\n",
    "if IS_RUNNING_LOCALLY:\n",
    "    df = df.sample(1_000, random_state=SEED)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7711f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Interaction\"] = (df[\"Ki (nM)\"] <= INTERACTION_THRESHOLD).astype(int)\n",
    "\n",
    "df[\"Embeddings\"] = df.apply(\n",
    "    lambda x: np.concatenate(\n",
    "        (\n",
    "            x[\"ECPF\"].flatten(),\n",
    "            x[\"Topological Torsion\"].flatten(),\n",
    "            x[\"Protein Embedding\"],\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7b4456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(df[\"Embeddings\"].to_numpy()))\n",
    "y = df[\"Interaction\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3360f8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (640, 832), (640,)\n",
      "Validation set: (160, 832), (160,)\n",
      "Test set: (200, 832), (200,)\n"
     ]
    }
   ],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=SEED,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_temp, y_temp, test_size=VALID_SIZE, random_state=SEED\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Train set: {X_train.shape}, {y_train.shape}\\n\"\n",
    "    f\"Validation set: {X_valid.shape}, {y_valid.shape}\\n\"\n",
    "    f\"Test set: {X_test.shape}, {y_test.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405c763c",
   "metadata": {},
   "source": [
    "Based on the amount of records in the datasets, for hyperparameter tuning we will use only 10% of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "175c3507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for hyperparameter tuning: (1000, 832), (1000,)\n"
     ]
    }
   ],
   "source": [
    "if IS_RUNNING_LOCALLY:\n",
    "    X_hyperparameter_tuning = X\n",
    "    y_hyperparameter_tuning = y\n",
    "else:\n",
    "    X_hyperparameter_tuning, _, y_hyperparameter_tuning, _ = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        train_size=HYPERPARAMETER_TUNING_DATASET_SIZE,\n",
    "        random_state=SEED,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"Dataset for hyperparameter tuning: {X_hyperparameter_tuning.shape}, {y_hyperparameter_tuning.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8764e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, define the Trainable class for your model\n",
    "# You need to implement:\n",
    "#  - setup (with dataset and model initialization),\n",
    "#  - step (for training and evaluation),\n",
    "#  - save_checkpoint (to save the model),\n",
    "#  - load_checkpoint (to load the model from a checkpoint).\n",
    "class LGBMTrainable(tune.Trainable):\n",
    "    SHOULD_SET_EVAL_SET = True  # LightGBM supports eval_set\n",
    "\n",
    "    fixed_params = {\n",
    "        \"random_state\": SEED,\n",
    "        \"n_jobs\": -1,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "    def setup_dataset(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def setup_skf(self, n_splits, seed):\n",
    "        self.skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    def setup(self, config):\n",
    "        self.setup_dataset(X_hyperparameter_tuning, y_hyperparameter_tuning)\n",
    "        self.setup_skf(N_SPLITS, LGBMTrainable.fixed_params[\"random_state\"])\n",
    "\n",
    "        self.model = LGBMClassifier(**config, **LGBMTrainable.fixed_params)\n",
    "\n",
    "    def calculate_metrics(self, y_true, y_pred_proba):\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "        return {\n",
    "            \"loss\": 1 - f1_score(y_true, y_pred),\n",
    "            \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"f1_score\": f1_score(y_true, y_pred),\n",
    "            \"precision\": precision_score(y_true, y_pred),\n",
    "            \"recall\": recall_score(y_true, y_pred),\n",
    "            \"roc_auc\": roc_auc_score(y_true, y_pred_proba),\n",
    "            \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        }\n",
    "\n",
    "    def step(self):\n",
    "        cv_scores = []\n",
    "        for train_idx, valid_idx in self.skf.split(self.X, self.y):\n",
    "            X_train_fold, X_valid_fold = self.X[train_idx], self.X[valid_idx]\n",
    "            y_train_fold, y_valid_fold = self.y[train_idx], self.y[valid_idx]\n",
    "\n",
    "            self.model.fit(\n",
    "                X_train_fold,\n",
    "                y_train_fold,\n",
    "                **(\n",
    "                    {\"eval_set\": [(X_valid_fold, y_valid_fold)]}\n",
    "                    if LGBMTrainable.SHOULD_SET_EVAL_SET\n",
    "                    else {}\n",
    "                ),\n",
    "            )\n",
    "            y_pred_proba = self.model.predict_proba(X_valid_fold)[:, 1]\n",
    "\n",
    "            cv_scores.append(self.calculate_metrics(y_valid_fold, y_pred_proba))\n",
    "\n",
    "        return {\n",
    "            \"loss\": np.mean([score[\"loss\"] for score in cv_scores]),\n",
    "            \"accuracy\": np.mean([score[\"accuracy\"] for score in cv_scores]),\n",
    "            \"f1_score\": np.mean([score[\"f1_score\"] for score in cv_scores]),\n",
    "            \"precision\": np.mean([score[\"precision\"] for score in cv_scores]),\n",
    "            \"recall\": np.mean([score[\"recall\"] for score in cv_scores]),\n",
    "            \"roc_auc\": np.mean([score[\"roc_auc\"] for score in cv_scores]),\n",
    "            \"balanced_accuracy\": np.mean(\n",
    "                [score[\"balanced_accuracy\"] for score in cv_scores]\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir):\n",
    "        checkpoint_path = f\"{checkpoint_dir}/model.pkl\"\n",
    "        self.model.booster_.save_model(checkpoint_path)\n",
    "        return {\"path\": checkpoint_path}\n",
    "\n",
    "    def load_checkpoint(self, checkpoint):\n",
    "        if not isinstance(checkpoint, dict):\n",
    "            raise ValueError(\n",
    "                \"Checkpoint must be a dictionary containing the path to the model.\"\n",
    "            )\n",
    "        self.model._Booster = lgb.Booster(model_file=checkpoint[\"path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a7214e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, you need to define the search space for hyperparameters.\n",
    "# It is a function that takes an `optuna.Trial` object and suggests hyperparameters.\n",
    "def define_search_space(trial: optuna.Trial):\n",
    "    trial.suggest_int(\"n_estimators\", 10, 200)\n",
    "    trial.suggest_float(\"learning_rate\", 1e-4, 0.3, log=True)\n",
    "    trial.suggest_int(\"num_leaves\", 20, 100)\n",
    "    trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    trial.suggest_int(\"min_child_samples\", 5, 20)\n",
    "    trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "    trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
    "    trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True)\n",
    "    trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True)\n",
    "\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47ce355f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 09:48:17,669\tINFO worker.py:1888 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "# Ensure Ray is initialized (important in Jupyter)\n",
    "ray.shutdown()  # Clean up any previous Ray state\n",
    "if not ray.is_initialized():\n",
    "    ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a9b5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the Ray Tune with Optuna run\n",
    "TRAINABLE = LGBMTrainable\n",
    "STUDY_NAME = \"LGBM_Optimization\"\n",
    "MAX_TRAIN_ITERS_PER_TRIAL = 20\n",
    "METRIC = \"roc_auc\"\n",
    "MODE = \"max\"\n",
    "N_TRIALS = 20\n",
    "RESOURCES = {\"cpu\": 1, \"gpu\": 0}  # Adjust based on environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f16fff12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-06-01 09:49:27</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:05.74        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.8/18.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=18<br>Bracket: Iter 64.000: None | Iter 16.000: 0.6956352591350418 | Iter 4.000: 0.6929345936330883 | Iter 1.000: 0.6852039838746529<br>Logical resource usage: 1.0/11 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  colsample_bytree</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_samples</th><th style=\"text-align: right;\">  n_estimators</th><th style=\"text-align: right;\">  num_leaves</th><th style=\"text-align: right;\">  reg_alpha</th><th style=\"text-align: right;\">  reg_lambda</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  f1_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>LGBMTrainable_3f0b3194</td><td>TERMINATED</td><td>127.0.0.1:4101</td><td style=\"text-align: right;\">          0.529042</td><td style=\"text-align: right;\">    0.202185   </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                  7</td><td style=\"text-align: right;\">            81</td><td style=\"text-align: right;\">          79</td><td style=\"text-align: right;\">0.624576   </td><td style=\"text-align: right;\"> 0.0025706  </td><td style=\"text-align: right;\">   0.577997</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">       53.118   </td><td style=\"text-align: right;\">0.66307 </td><td style=\"text-align: right;\">  0.870997</td><td style=\"text-align: right;\">  0.33693 </td></tr>\n",
       "<tr><td>LGBMTrainable_cad49c3e</td><td>TERMINATED</td><td>127.0.0.1:4104</td><td style=\"text-align: right;\">          0.591702</td><td style=\"text-align: right;\">    0.000117917</td><td style=\"text-align: right;\">          9</td><td style=\"text-align: right;\">                  8</td><td style=\"text-align: right;\">           145</td><td style=\"text-align: right;\">          98</td><td style=\"text-align: right;\">5.47243e-06</td><td style=\"text-align: right;\"> 0.000528212</td><td style=\"text-align: right;\">   0.590912</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        7.09697 </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">  0.863001</td><td style=\"text-align: right;\">  0       </td></tr>\n",
       "<tr><td>LGBMTrainable_3469ebff</td><td>TERMINATED</td><td>127.0.0.1:4106</td><td style=\"text-align: right;\">          0.728035</td><td style=\"text-align: right;\">    0.00102953 </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                  9</td><td style=\"text-align: right;\">            92</td><td style=\"text-align: right;\">          69</td><td style=\"text-align: right;\">0.116569   </td><td style=\"text-align: right;\"> 6.26706e-07</td><td style=\"text-align: right;\">   0.683181</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        2.02701 </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">  0.863001</td><td style=\"text-align: right;\">  0       </td></tr>\n",
       "<tr><td>LGBMTrainable_7faca523</td><td>TERMINATED</td><td>127.0.0.1:4107</td><td style=\"text-align: right;\">          0.974443</td><td style=\"text-align: right;\">    0.0114788  </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                  7</td><td style=\"text-align: right;\">           108</td><td style=\"text-align: right;\">          23</td><td style=\"text-align: right;\">4.90556    </td><td style=\"text-align: right;\"> 0.188615   </td><td style=\"text-align: right;\">   0.532526</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        4.73599 </td><td style=\"text-align: right;\">0.724754</td><td style=\"text-align: right;\">  0.883992</td><td style=\"text-align: right;\">  0.275246</td></tr>\n",
       "<tr><td>LGBMTrainable_1423afc7</td><td>TERMINATED</td><td>127.0.0.1:4112</td><td style=\"text-align: right;\">          0.517194</td><td style=\"text-align: right;\">    0.000218584</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                  6</td><td style=\"text-align: right;\">            68</td><td style=\"text-align: right;\">          75</td><td style=\"text-align: right;\">1.52716    </td><td style=\"text-align: right;\"> 2.13314e-06</td><td style=\"text-align: right;\">   0.747588</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">       57.9873  </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">  0.863001</td><td style=\"text-align: right;\">  0       </td></tr>\n",
       "<tr><td>LGBMTrainable_4f1d0bf1</td><td>TERMINATED</td><td>127.0.0.1:4127</td><td style=\"text-align: right;\">          0.887566</td><td style=\"text-align: right;\">    0.00121299 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                  7</td><td style=\"text-align: right;\">           136</td><td style=\"text-align: right;\">          62</td><td style=\"text-align: right;\">2.85424    </td><td style=\"text-align: right;\"> 1.13096    </td><td style=\"text-align: right;\">   0.984792</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        7.90122 </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">  0.863001</td><td style=\"text-align: right;\">  0       </td></tr>\n",
       "<tr><td>LGBMTrainable_b904d5c0</td><td>TERMINATED</td><td>127.0.0.1:4128</td><td style=\"text-align: right;\">          0.694339</td><td style=\"text-align: right;\">    0.160498   </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                  5</td><td style=\"text-align: right;\">           124</td><td style=\"text-align: right;\">          27</td><td style=\"text-align: right;\">2.76784e-06</td><td style=\"text-align: right;\"> 0.2875     </td><td style=\"text-align: right;\">   0.662665</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        3.48493 </td><td style=\"text-align: right;\">0.606887</td><td style=\"text-align: right;\">  0.880006</td><td style=\"text-align: right;\">  0.393113</td></tr>\n",
       "<tr><td>LGBMTrainable_deb94f9f</td><td>TERMINATED</td><td>127.0.0.1:4137</td><td style=\"text-align: right;\">          0.993443</td><td style=\"text-align: right;\">    0.000948076</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 17</td><td style=\"text-align: right;\">            78</td><td style=\"text-align: right;\">          63</td><td style=\"text-align: right;\">0.0891667  </td><td style=\"text-align: right;\"> 6.14386e-07</td><td style=\"text-align: right;\">   0.537275</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.90639 </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">  0.863001</td><td style=\"text-align: right;\">  0       </td></tr>\n",
       "<tr><td>LGBMTrainable_4b250b73</td><td>TERMINATED</td><td>127.0.0.1:4139</td><td style=\"text-align: right;\">          0.679233</td><td style=\"text-align: right;\">    0.0684634  </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 17</td><td style=\"text-align: right;\">            11</td><td style=\"text-align: right;\">          77</td><td style=\"text-align: right;\">1.10363e-07</td><td style=\"text-align: right;\"> 0.586045   </td><td style=\"text-align: right;\">   0.537022</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.808692</td><td style=\"text-align: right;\">0.96    </td><td style=\"text-align: right;\">  0.864997</td><td style=\"text-align: right;\">  0.04    </td></tr>\n",
       "<tr><td>LGBMTrainable_620b839c</td><td>TERMINATED</td><td>127.0.0.1:4140</td><td style=\"text-align: right;\">          0.818779</td><td style=\"text-align: right;\">    0.0014144  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">           129</td><td style=\"text-align: right;\">          25</td><td style=\"text-align: right;\">0.965861   </td><td style=\"text-align: right;\"> 0.000177801</td><td style=\"text-align: right;\">   0.864803</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        4.11671 </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">  0.863001</td><td style=\"text-align: right;\">  0       </td></tr>\n",
       "<tr><td>LGBMTrainable_959889be</td><td>TERMINATED</td><td>127.0.0.1:4141</td><td style=\"text-align: right;\">          0.761366</td><td style=\"text-align: right;\">    0.0302022  </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 17</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">          81</td><td style=\"text-align: right;\">7.04481e-05</td><td style=\"text-align: right;\"> 1.69345e-08</td><td style=\"text-align: right;\">   0.746898</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        6.19303 </td><td style=\"text-align: right;\">0.740079</td><td style=\"text-align: right;\">  0.88    </td><td style=\"text-align: right;\">  0.259921</td></tr>\n",
       "<tr><td>LGBMTrainable_89bb204c</td><td>TERMINATED</td><td>127.0.0.1:4143</td><td style=\"text-align: right;\">          0.624646</td><td style=\"text-align: right;\">    0.000128612</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 13</td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">          71</td><td style=\"text-align: right;\">4.93681e-05</td><td style=\"text-align: right;\"> 0.06309    </td><td style=\"text-align: right;\">   0.953783</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.1863  </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">  0.863001</td><td style=\"text-align: right;\">  0       </td></tr>\n",
       "<tr><td>LGBMTrainable_222010b5</td><td>TERMINATED</td><td>127.0.0.1:4146</td><td style=\"text-align: right;\">          0.816702</td><td style=\"text-align: right;\">    0.000185212</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 19</td><td style=\"text-align: right;\">            53</td><td style=\"text-align: right;\">          43</td><td style=\"text-align: right;\">0.69686    </td><td style=\"text-align: right;\"> 0.171021   </td><td style=\"text-align: right;\">   0.90406 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.41501 </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">  0.863001</td><td style=\"text-align: right;\">  0       </td></tr>\n",
       "<tr><td>LGBMTrainable_18e02911</td><td>TERMINATED</td><td>127.0.0.1:4148</td><td style=\"text-align: right;\">          0.555026</td><td style=\"text-align: right;\">    0.126922   </td><td style=\"text-align: right;\">          9</td><td style=\"text-align: right;\">                 19</td><td style=\"text-align: right;\">            45</td><td style=\"text-align: right;\">          63</td><td style=\"text-align: right;\">1.12568e-06</td><td style=\"text-align: right;\"> 6.98184e-05</td><td style=\"text-align: right;\">   0.659002</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        2.55485 </td><td style=\"text-align: right;\">0.64308 </td><td style=\"text-align: right;\">  0.876002</td><td style=\"text-align: right;\">  0.35692 </td></tr>\n",
       "<tr><td>LGBMTrainable_f47c7efe</td><td>TERMINATED</td><td>127.0.0.1:4149</td><td style=\"text-align: right;\">          0.507797</td><td style=\"text-align: right;\">    0.175285   </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                  5</td><td style=\"text-align: right;\">           192</td><td style=\"text-align: right;\">          44</td><td style=\"text-align: right;\">1.39826e-08</td><td style=\"text-align: right;\"> 0.00136437 </td><td style=\"text-align: right;\">   0.767802</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        3.18901 </td><td style=\"text-align: right;\">0.64422 </td><td style=\"text-align: right;\">  0.871006</td><td style=\"text-align: right;\">  0.35578 </td></tr>\n",
       "<tr><td>LGBMTrainable_5a5a8b0b</td><td>TERMINATED</td><td>127.0.0.1:4150</td><td style=\"text-align: right;\">          0.740991</td><td style=\"text-align: right;\">    0.270271   </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 13</td><td style=\"text-align: right;\">           194</td><td style=\"text-align: right;\">          90</td><td style=\"text-align: right;\">0.00144417 </td><td style=\"text-align: right;\"> 1.17587e-08</td><td style=\"text-align: right;\">   0.771775</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        4.36852 </td><td style=\"text-align: right;\">0.607202</td><td style=\"text-align: right;\">  0.877   </td><td style=\"text-align: right;\">  0.392798</td></tr>\n",
       "<tr><td>LGBMTrainable_2db4920a</td><td>TERMINATED</td><td>127.0.0.1:4152</td><td style=\"text-align: right;\">          0.738869</td><td style=\"text-align: right;\">    0.0309653  </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 14</td><td style=\"text-align: right;\">           179</td><td style=\"text-align: right;\">          90</td><td style=\"text-align: right;\">0.00140176 </td><td style=\"text-align: right;\"> 1.12851e-08</td><td style=\"text-align: right;\">   0.786328</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        6.02237 </td><td style=\"text-align: right;\">0.621409</td><td style=\"text-align: right;\">  0.883992</td><td style=\"text-align: right;\">  0.378591</td></tr>\n",
       "<tr><td>LGBMTrainable_637b9505</td><td>TERMINATED</td><td>127.0.0.1:4154</td><td style=\"text-align: right;\">          0.751873</td><td style=\"text-align: right;\">    0.0303243  </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 13</td><td style=\"text-align: right;\">           168</td><td style=\"text-align: right;\">          88</td><td style=\"text-align: right;\">0.000305175</td><td style=\"text-align: right;\"> 2.04296e-08</td><td style=\"text-align: right;\">   0.767424</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">       22.4799  </td><td style=\"text-align: right;\">0.617446</td><td style=\"text-align: right;\">  0.88199 </td><td style=\"text-align: right;\">  0.382554</td></tr>\n",
       "<tr><td>LGBMTrainable_5339dbd8</td><td>TERMINATED</td><td>127.0.0.1:4164</td><td style=\"text-align: right;\">          0.748533</td><td style=\"text-align: right;\">    0.0337139  </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 13</td><td style=\"text-align: right;\">           179</td><td style=\"text-align: right;\">          88</td><td style=\"text-align: right;\">0.000536592</td><td style=\"text-align: right;\"> 5.80171e-08</td><td style=\"text-align: right;\">   0.780688</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        6.53848 </td><td style=\"text-align: right;\">0.611808</td><td style=\"text-align: right;\">  0.884993</td><td style=\"text-align: right;\">  0.388192</td></tr>\n",
       "<tr><td>LGBMTrainable_dd132d3d</td><td>TERMINATED</td><td>127.0.0.1:4167</td><td style=\"text-align: right;\">          0.665927</td><td style=\"text-align: right;\">    0.0243241  </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">                 15</td><td style=\"text-align: right;\">           166</td><td style=\"text-align: right;\">          44</td><td style=\"text-align: right;\">0.00103963 </td><td style=\"text-align: right;\"> 6.24307    </td><td style=\"text-align: right;\">   0.689208</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">       24.2075  </td><td style=\"text-align: right;\">0.66798 </td><td style=\"text-align: right;\">  0.880998</td><td style=\"text-align: right;\">  0.33202 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 09:49:27,214\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/milosz/ray_results/LGBM_Optimization' in 0.0082s.\n",
      "2025-06-01 09:49:27,218\tINFO tune.py:1041 -- Total run time: 65.76 seconds (65.73 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'n_estimators': 68, 'learning_rate': 0.0002185837053086611, 'num_leaves': 75, 'max_depth': 6, 'min_child_samples': 6, 'subsample': 0.7475884550556351, 'colsample_bytree': 0.5171942605576092, 'reg_alpha': 1.5271567592511939, 'reg_lambda': 2.133142332373e-06}\n",
      "Best roc_auc found: 0.6965\n"
     ]
    }
   ],
   "source": [
    "# Define the RunConfig\n",
    "# It is important to define stop condition!\n",
    "run_config = RunConfig(\n",
    "    callbacks=[\n",
    "        # WandbLoggerCallback(project=study_name),\n",
    "    ],\n",
    "    stop={\"training_iteration\": MAX_TRAIN_ITERS_PER_TRIAL},\n",
    "    checkpoint_config=CheckpointConfig(checkpoint_at_end=True),\n",
    "    name=STUDY_NAME,\n",
    ")\n",
    "\n",
    "# Define the Optuna search algorithm\n",
    "optuna_search = OptunaSearch(\n",
    "    define_search_space,\n",
    "    metric=METRIC,\n",
    "    mode=MODE,\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "    study_name=STUDY_NAME,\n",
    ")\n",
    "\n",
    "# Create the Tuner object\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(TRAINABLE, resources=RESOURCES),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        scheduler=ASHAScheduler(metric=METRIC, mode=MODE),\n",
    "        num_samples=N_TRIALS,\n",
    "        search_alg=optuna_search,\n",
    "    ),\n",
    "    run_config=run_config,\n",
    ")\n",
    "\n",
    "# Start the hyperparameter tuning process\n",
    "results = tuner.fit()\n",
    "\n",
    "best_result = results.get_best_result(metric=METRIC, mode=MODE)\n",
    "best_params = best_result.config\n",
    "print(f\"Best hyperparameters found: {best_params}\")\n",
    "best_metric = best_result.metrics[METRIC]\n",
    "print(f\"Best {METRIC} found: {best_metric:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86578fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milosz/SemestrVIII/LSC/proj/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lgbm_best_params = {**best_params, **LGBMTrainable.fixed_params}\n",
    "lgbm_clf = LGBMClassifier(**lgbm_best_params)\n",
    "lgbm_clf.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    **({\"eval_set\": [(X_valid, y_valid)]} if LGBMTrainable.SHOULD_SET_EVAL_SET else {}),\n",
    ")\n",
    "\n",
    "y_pred_proba = lgbm_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36ecc807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Classifier Metrics:\n",
      "    accuracy: 0.8650\n",
      "    f1_score: 0.0000\n",
      "    precision: 0.0000\n",
      "    recall: 0.0000\n",
      "    roc_auc: 0.6611\n",
      "    balanced_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milosz/SemestrVIII/LSC/proj/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf_metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"f1_score\": f1_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\": recall_score(y_test, y_pred),\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_pred_proba),\n",
    "    \"balanced_accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "}\n",
    "print(\"LGBM Classifier Metrics:\")\n",
    "for metric, value in lgbm_clf_metrics.items():\n",
    "    print(f\"    {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d8c54995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, define the Trainable class for your model\n",
    "# You need to implement:\n",
    "#  - setup (with dataset and model initialization),\n",
    "#  - step (for training and evaluation),\n",
    "#  - save_checkpoint (to save the model),\n",
    "#  - load_checkpoint (to load the model from a checkpoint).\n",
    "class RFTrainable(tune.Trainable):\n",
    "    SHOULD_SET_EVAL_SET = False  # RandomForest does not support eval_set\n",
    "\n",
    "    fixed_params = {\n",
    "        \"random_state\": SEED,\n",
    "        \"n_jobs\": -1,\n",
    "        \"verbose\": 0,\n",
    "    }\n",
    "\n",
    "    def setup_dataset(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def setup_skf(self, n_splits, seed):\n",
    "        self.skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    def setup(self, config):\n",
    "        self.setup_dataset(X_hyperparameter_tuning, y_hyperparameter_tuning)\n",
    "        self.setup_skf(N_SPLITS, RFTrainable.fixed_params[\"random_state\"])\n",
    "\n",
    "        self.model = RandomForestClassifier(**config, **RFTrainable.fixed_params)\n",
    "\n",
    "    def calculate_metrics(self, y_true, y_pred_proba):\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "        return {\n",
    "            \"loss\": 1 - f1_score(y_true, y_pred),\n",
    "            \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"f1_score\": f1_score(y_true, y_pred),\n",
    "            \"precision\": precision_score(y_true, y_pred),\n",
    "            \"recall\": recall_score(y_true, y_pred),\n",
    "            \"roc_auc\": roc_auc_score(y_true, y_pred_proba),\n",
    "            \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        }\n",
    "\n",
    "    def step(self):\n",
    "        cv_scores = []\n",
    "        for train_idx, valid_idx in self.skf.split(self.X, self.y):\n",
    "            X_train_fold, X_valid_fold = self.X[train_idx], self.X[valid_idx]\n",
    "            y_train_fold, y_valid_fold = self.y[train_idx], self.y[valid_idx]\n",
    "\n",
    "            self.model.fit(\n",
    "                X_train_fold,\n",
    "                y_train_fold,\n",
    "                **(\n",
    "                    {\"eval_set\": [(X_valid_fold, y_valid_fold)]}\n",
    "                    if RFTrainable.SHOULD_SET_EVAL_SET\n",
    "                    else {}\n",
    "                ),\n",
    "            )\n",
    "            y_pred_proba = self.model.predict_proba(X_valid_fold)[:, 1]\n",
    "\n",
    "            cv_scores.append(self.calculate_metrics(y_valid_fold, y_pred_proba))\n",
    "\n",
    "        return {\n",
    "            \"loss\": np.mean([score[\"loss\"] for score in cv_scores]),\n",
    "            \"accuracy\": np.mean([score[\"accuracy\"] for score in cv_scores]),\n",
    "            \"f1_score\": np.mean([score[\"f1_score\"] for score in cv_scores]),\n",
    "            \"precision\": np.mean([score[\"precision\"] for score in cv_scores]),\n",
    "            \"recall\": np.mean([score[\"recall\"] for score in cv_scores]),\n",
    "            \"roc_auc\": np.mean([score[\"roc_auc\"] for score in cv_scores]),\n",
    "            \"balanced_accuracy\": np.mean(\n",
    "                [score[\"balanced_accuracy\"] for score in cv_scores]\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir):\n",
    "        checkpoint_path = f\"{checkpoint_dir}/model.pkl\"\n",
    "        with open(checkpoint_path, \"wb\") as f:\n",
    "            pickle.dump(self.model, f)\n",
    "        return {\"path\": checkpoint_path}\n",
    "\n",
    "    def load_checkpoint(self, checkpoint):\n",
    "        if not isinstance(checkpoint, dict):\n",
    "            raise ValueError(\n",
    "                \"Checkpoint must be a dictionary containing the path to the model.\"\n",
    "            )\n",
    "        with open(checkpoint[\"path\"], \"rb\") as f:\n",
    "            self.model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6df0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, you need to define the search space for hyperparameters.\n",
    "# It is a function that takes an `optuna.Trial` object and suggests hyperparameters.\n",
    "def define_search_space(trial: optuna.Trial):\n",
    "    trial.suggest_int(\"n_estimators\", 10, 100)\n",
    "    trial.suggest_int(\"max_depth\", 3, 15)\n",
    "    trial.suggest_int(\"min_samples_split\", 2, 15)\n",
    "    trial.suggest_int(\"min_samples_leaf\", 1, 15)\n",
    "    trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
    "\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "47fa2b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 10:00:49,986\tINFO worker.py:1888 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "# Ensure Ray is initialized (important in Jupyter)\n",
    "ray.shutdown()  # Clean up any previous Ray state\n",
    "if not ray.is_initialized():\n",
    "    ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a80fa0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the Ray Tune with Optuna run\n",
    "TRAINABLE = RFTrainable\n",
    "STUDY_NAME = \"RF_Optimization\"\n",
    "MAX_TRAIN_ITERS_PER_TRIAL = 20\n",
    "METRIC = \"balanced_accuracy\"\n",
    "MODE = \"max\"\n",
    "N_TRIALS = 20\n",
    "RESOURCES = {\"cpu\": 1, \"gpu\": 0}  # Adjust based on environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1854b79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-06-01 10:01:26</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:33.38        </td></tr>\n",
       "<tr><td>Memory:      </td><td>12.2/18.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=14<br>Bracket: Iter 64.000: None | Iter 16.000: 0.6013103724463745 | Iter 4.000: 0.6013103724463745 | Iter 1.000: 0.596317424548469<br>Logical resource usage: 1.0/11 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  max_depth</th><th>max_features  </th><th style=\"text-align: right;\">  min_samples_leaf</th><th style=\"text-align: right;\">  min_samples_split</th><th style=\"text-align: right;\">  n_estimators</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  f1_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>RFTrainable_4cb619fe</td><td>TERMINATED</td><td>127.0.0.1:4614</td><td style=\"text-align: right;\">         15</td><td>sqrt          </td><td style=\"text-align: right;\">                 9</td><td style=\"text-align: right;\">                 12</td><td style=\"text-align: right;\">            44</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        4.16502 </td><td style=\"text-align: right;\">0.695404</td><td style=\"text-align: right;\">  0.883995</td><td style=\"text-align: right;\">  0.304596</td></tr>\n",
       "<tr><td>RFTrainable_94d8faaa</td><td>TERMINATED</td><td>127.0.0.1:4621</td><td style=\"text-align: right;\">         10</td><td>sqrt          </td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">                 11</td><td style=\"text-align: right;\">            88</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        6.97509 </td><td style=\"text-align: right;\">0.684184</td><td style=\"text-align: right;\">  0.880003</td><td style=\"text-align: right;\">  0.315816</td></tr>\n",
       "<tr><td>RFTrainable_22dc529d</td><td>TERMINATED</td><td>127.0.0.1:4623</td><td style=\"text-align: right;\">          5</td><td>              </td><td style=\"text-align: right;\">                 8</td><td style=\"text-align: right;\">                  6</td><td style=\"text-align: right;\">            26</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.736422</td><td style=\"text-align: right;\">0.709839</td><td style=\"text-align: right;\">  0.878996</td><td style=\"text-align: right;\">  0.290161</td></tr>\n",
       "<tr><td>RFTrainable_8b0afbf4</td><td>TERMINATED</td><td>127.0.0.1:4625</td><td style=\"text-align: right;\">          6</td><td>sqrt          </td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">                  7</td><td style=\"text-align: right;\">            22</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        3.23127 </td><td style=\"text-align: right;\">0.675737</td><td style=\"text-align: right;\">  0.885991</td><td style=\"text-align: right;\">  0.324263</td></tr>\n",
       "<tr><td>RFTrainable_89aaafa2</td><td>TERMINATED</td><td>127.0.0.1:4628</td><td style=\"text-align: right;\">          3</td><td>              </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">            63</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.902519</td><td style=\"text-align: right;\">0.753773</td><td style=\"text-align: right;\">  0.878996</td><td style=\"text-align: right;\">  0.246227</td></tr>\n",
       "<tr><td>RFTrainable_608b9da7</td><td>TERMINATED</td><td>127.0.0.1:4630</td><td style=\"text-align: right;\">          6</td><td>              </td><td style=\"text-align: right;\">                11</td><td style=\"text-align: right;\">                  3</td><td style=\"text-align: right;\">            83</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.63043 </td><td style=\"text-align: right;\">0.723124</td><td style=\"text-align: right;\">  0.878996</td><td style=\"text-align: right;\">  0.276876</td></tr>\n",
       "<tr><td>RFTrainable_8b9ae40c</td><td>TERMINATED</td><td>127.0.0.1:4632</td><td style=\"text-align: right;\">         14</td><td>              </td><td style=\"text-align: right;\">                10</td><td style=\"text-align: right;\">                  5</td><td style=\"text-align: right;\">            13</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        1.96256 </td><td style=\"text-align: right;\">0.683822</td><td style=\"text-align: right;\">  0.879997</td><td style=\"text-align: right;\">  0.316178</td></tr>\n",
       "<tr><td>RFTrainable_42a81cc4</td><td>TERMINATED</td><td>127.0.0.1:4649</td><td style=\"text-align: right;\">         15</td><td>              </td><td style=\"text-align: right;\">                15</td><td style=\"text-align: right;\">                 12</td><td style=\"text-align: right;\">            26</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.682153</td><td style=\"text-align: right;\">0.719265</td><td style=\"text-align: right;\">  0.877995</td><td style=\"text-align: right;\">  0.280735</td></tr>\n",
       "<tr><td>RFTrainable_240b0c6d</td><td>TERMINATED</td><td>127.0.0.1:4651</td><td style=\"text-align: right;\">          5</td><td>              </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                  2</td><td style=\"text-align: right;\">            18</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.400565</td><td style=\"text-align: right;\">0.734906</td><td style=\"text-align: right;\">  0.875996</td><td style=\"text-align: right;\">  0.265094</td></tr>\n",
       "<tr><td>RFTrainable_f8398017</td><td>TERMINATED</td><td>127.0.0.1:4653</td><td style=\"text-align: right;\">          6</td><td>              </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                  9</td><td style=\"text-align: right;\">            42</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.863656</td><td style=\"text-align: right;\">0.688925</td><td style=\"text-align: right;\">  0.881001</td><td style=\"text-align: right;\">  0.311075</td></tr>\n",
       "<tr><td>RFTrainable_71c1ef1d</td><td>TERMINATED</td><td>127.0.0.1:4655</td><td style=\"text-align: right;\">          5</td><td>              </td><td style=\"text-align: right;\">                13</td><td style=\"text-align: right;\">                  2</td><td style=\"text-align: right;\">            80</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.21083 </td><td style=\"text-align: right;\">0.739402</td><td style=\"text-align: right;\">  0.876997</td><td style=\"text-align: right;\">  0.260598</td></tr>\n",
       "<tr><td>RFTrainable_4fdd0bcf</td><td>TERMINATED</td><td>127.0.0.1:4658</td><td style=\"text-align: right;\">         10</td><td>log2          </td><td style=\"text-align: right;\">                14</td><td style=\"text-align: right;\">                 15</td><td style=\"text-align: right;\">            56</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.18456 </td><td style=\"text-align: right;\">0.8189  </td><td style=\"text-align: right;\">  0.874998</td><td style=\"text-align: right;\">  0.1811  </td></tr>\n",
       "<tr><td>RFTrainable_1bfe0ec8</td><td>TERMINATED</td><td>127.0.0.1:4660</td><td style=\"text-align: right;\">         10</td><td>sqrt          </td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">                 15</td><td style=\"text-align: right;\">            92</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        6.36906 </td><td style=\"text-align: right;\">0.680554</td><td style=\"text-align: right;\">  0.882997</td><td style=\"text-align: right;\">  0.319446</td></tr>\n",
       "<tr><td>RFTrainable_f4e9adea</td><td>TERMINATED</td><td>127.0.0.1:4662</td><td style=\"text-align: right;\">         10</td><td>sqrt          </td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">                  7</td><td style=\"text-align: right;\">            98</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        9.12688 </td><td style=\"text-align: right;\">0.669042</td><td style=\"text-align: right;\">  0.879005</td><td style=\"text-align: right;\">  0.330958</td></tr>\n",
       "<tr><td>RFTrainable_86070d37</td><td>TERMINATED</td><td>127.0.0.1:4667</td><td style=\"text-align: right;\">         10</td><td>sqrt          </td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">                  7</td><td style=\"text-align: right;\">            95</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        9.22272 </td><td style=\"text-align: right;\">0.658626</td><td style=\"text-align: right;\">  0.881001</td><td style=\"text-align: right;\">  0.341374</td></tr>\n",
       "<tr><td>RFTrainable_6fb349b2</td><td>TERMINATED</td><td>127.0.0.1:4670</td><td style=\"text-align: right;\">         10</td><td>sqrt          </td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">                  7</td><td style=\"text-align: right;\">            98</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        8.64183 </td><td style=\"text-align: right;\">0.669042</td><td style=\"text-align: right;\">  0.879005</td><td style=\"text-align: right;\">  0.330958</td></tr>\n",
       "<tr><td>RFTrainable_d9ec5103</td><td>TERMINATED</td><td>127.0.0.1:4672</td><td style=\"text-align: right;\">         10</td><td>sqrt          </td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">                  7</td><td style=\"text-align: right;\">            97</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.495535</td><td style=\"text-align: right;\">0.683841</td><td style=\"text-align: right;\">  0.884996</td><td style=\"text-align: right;\">  0.316159</td></tr>\n",
       "<tr><td>RFTrainable_e93096cc</td><td>TERMINATED</td><td>127.0.0.1:4675</td><td style=\"text-align: right;\">          8</td><td>sqrt          </td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">                  7</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.541715</td><td style=\"text-align: right;\">0.681698</td><td style=\"text-align: right;\">  0.885994</td><td style=\"text-align: right;\">  0.318302</td></tr>\n",
       "<tr><td>RFTrainable_4b058252</td><td>TERMINATED</td><td>127.0.0.1:4677</td><td style=\"text-align: right;\">          8</td><td>sqrt          </td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">                 15</td><td style=\"text-align: right;\">            69</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.410329</td><td style=\"text-align: right;\">0.693254</td><td style=\"text-align: right;\">  0.88    </td><td style=\"text-align: right;\">  0.306746</td></tr>\n",
       "<tr><td>RFTrainable_87427bcb</td><td>TERMINATED</td><td>127.0.0.1:4679</td><td style=\"text-align: right;\">         12</td><td>sqrt          </td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">                 15</td><td style=\"text-align: right;\">            69</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.289532</td><td style=\"text-align: right;\">0.689312</td><td style=\"text-align: right;\">  0.881996</td><td style=\"text-align: right;\">  0.310688</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 10:01:26,386\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/milosz/ray_results/RF_Optimization' in 0.0112s.\n",
      "2025-06-01 10:01:26,390\tINFO tune.py:1041 -- Total run time: 33.41 seconds (33.37 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'n_estimators': 95, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Best balanced_accuracy found: 0.6055\n"
     ]
    }
   ],
   "source": [
    "# Define the RunConfig\n",
    "# It is important to define stop condition!\n",
    "run_config = RunConfig(\n",
    "    callbacks=[\n",
    "        # WandbLoggerCallback(project=study_name),\n",
    "    ],\n",
    "    stop={\"training_iteration\": MAX_TRAIN_ITERS_PER_TRIAL},\n",
    "    checkpoint_config=CheckpointConfig(checkpoint_at_end=True),\n",
    "    name=STUDY_NAME,\n",
    ")\n",
    "\n",
    "# Define the Optuna search algorithm\n",
    "optuna_search = OptunaSearch(\n",
    "    define_search_space,\n",
    "    metric=METRIC,\n",
    "    mode=MODE,\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "    study_name=STUDY_NAME,\n",
    ")\n",
    "\n",
    "# Create the Tuner object\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(TRAINABLE, resources=RESOURCES),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        scheduler=ASHAScheduler(metric=METRIC, mode=MODE),\n",
    "        num_samples=N_TRIALS,\n",
    "        search_alg=optuna_search,\n",
    "    ),\n",
    "    run_config=run_config,\n",
    ")\n",
    "\n",
    "# Start the hyperparameter tuning process\n",
    "results = tuner.fit()\n",
    "\n",
    "best_result = results.get_best_result(metric=METRIC, mode=MODE)\n",
    "best_params = best_result.config\n",
    "print(f\"Best hyperparameters found: {best_params}\")\n",
    "best_metric = best_result.metrics[METRIC]\n",
    "print(f\"Best {METRIC} found: {best_metric:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5256704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Classifier Metrics:\n",
      "    accuracy: 0.8850\n",
      "    f1_score: 0.3429\n",
      "    precision: 0.7500\n",
      "    recall: 0.2222\n",
      "    roc_auc: 0.6245\n",
      "    balanced_accuracy: 0.6053\n"
     ]
    }
   ],
   "source": [
    "rf_best_params = {**best_params, **RFTrainable.fixed_params}\n",
    "rf_clf = RandomForestClassifier(**rf_best_params)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "rf_clf_metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"f1_score\": f1_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\": recall_score(y_test, y_pred),\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_pred_proba),\n",
    "    \"balanced_accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "}\n",
    "print(\"RF Classifier Metrics:\")\n",
    "for metric, value in rf_clf_metrics.items():\n",
    "    print(f\"    {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f232b676",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_weight = (y_hyperparameter_tuning == 0).sum() / (\n",
    "    y_hyperparameter_tuning == 1\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5e0720ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, define the Trainable class for your model\n",
    "# You need to implement:\n",
    "#  - setup (with dataset and model initialization),\n",
    "#  - step (for training and evaluation),\n",
    "#  - save_checkpoint (to save the model),\n",
    "#  - load_checkpoint (to load the model from a checkpoint).\n",
    "class XGBTrainable(tune.Trainable):\n",
    "    SHOULD_SET_EVAL_SET = True  # XGBoost supports eval_set\n",
    "\n",
    "    fixed_params = {\n",
    "        \"scale_pos_weight\": scale_pos_weight,\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"random_state\": SEED,\n",
    "        \"n_jobs\": -1,\n",
    "        \"verbosity\": 0,\n",
    "    }\n",
    "\n",
    "    def setup_dataset(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def setup_skf(self, n_splits, seed):\n",
    "        self.skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    def setup(self, config):\n",
    "        self.setup_dataset(X_hyperparameter_tuning, y_hyperparameter_tuning)\n",
    "        self.setup_skf(N_SPLITS, XGBTrainable.fixed_params[\"random_state\"])\n",
    "\n",
    "        self.model = XGBClassifier(**config, **XGBTrainable.fixed_params)\n",
    "\n",
    "    def calculate_metrics(self, y_true, y_pred_proba):\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "        return {\n",
    "            \"loss\": 1 - f1_score(y_true, y_pred),\n",
    "            \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"f1_score\": f1_score(y_true, y_pred),\n",
    "            \"precision\": precision_score(y_true, y_pred),\n",
    "            \"recall\": recall_score(y_true, y_pred),\n",
    "            \"roc_auc\": roc_auc_score(y_true, y_pred_proba),\n",
    "            \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        }\n",
    "\n",
    "    def step(self):\n",
    "        cv_scores = []\n",
    "        for train_idx, valid_idx in self.skf.split(self.X, self.y):\n",
    "            X_train_fold, X_valid_fold = self.X[train_idx], self.X[valid_idx]\n",
    "            y_train_fold, y_valid_fold = self.y[train_idx], self.y[valid_idx]\n",
    "\n",
    "            self.model.fit(\n",
    "                X_train_fold,\n",
    "                y_train_fold,\n",
    "                **(\n",
    "                    {\"eval_set\": [(X_valid_fold, y_valid_fold)]}\n",
    "                    if XGBTrainable.SHOULD_SET_EVAL_SET\n",
    "                    else {}\n",
    "                ),\n",
    "            )\n",
    "            y_pred_proba = self.model.predict_proba(X_valid_fold)[:, 1]\n",
    "\n",
    "            cv_scores.append(self.calculate_metrics(y_valid_fold, y_pred_proba))\n",
    "\n",
    "        return {\n",
    "            \"loss\": np.mean([score[\"loss\"] for score in cv_scores]),\n",
    "            \"accuracy\": np.mean([score[\"accuracy\"] for score in cv_scores]),\n",
    "            \"f1_score\": np.mean([score[\"f1_score\"] for score in cv_scores]),\n",
    "            \"precision\": np.mean([score[\"precision\"] for score in cv_scores]),\n",
    "            \"recall\": np.mean([score[\"recall\"] for score in cv_scores]),\n",
    "            \"roc_auc\": np.mean([score[\"roc_auc\"] for score in cv_scores]),\n",
    "            \"balanced_accuracy\": np.mean(\n",
    "                [score[\"balanced_accuracy\"] for score in cv_scores]\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir):\n",
    "        checkpoint_path = f\"{checkpoint_dir}/model.pkl\"\n",
    "        with open(checkpoint_path, \"wb\") as f:\n",
    "            pickle.dump(self.model, f)\n",
    "        return {\"path\": checkpoint_path}\n",
    "\n",
    "    def load_checkpoint(self, checkpoint):\n",
    "        if not isinstance(checkpoint, dict):\n",
    "            raise ValueError(\n",
    "                \"Checkpoint must be a dictionary containing the path to the model.\"\n",
    "            )\n",
    "        with open(checkpoint[\"path\"], \"rb\") as f:\n",
    "            self.model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "080ecb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, you need to define the search space for hyperparameters.\n",
    "# It is a function that takes an `optuna.Trial` object and suggests hyperparameters.\n",
    "def define_search_space(trial: optuna.Trial):\n",
    "    trial.suggest_int(\"n_estimators\", 10, 100)\n",
    "    trial.suggest_float(\"learning_rate\", 1e-4, 0.3, log=True)\n",
    "    trial.suggest_int(\"max_depth\", 3, 12)\n",
    "    trial.suggest_float(\"min_child_weight\", 1, 10)\n",
    "    trial.suggest_float(\"gamma\", 0, 5)\n",
    "    trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "    trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
    "    trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True)\n",
    "    trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True)\n",
    "\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "99fa1453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 10:08:56,998\tINFO worker.py:1888 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "# Ensure Ray is initialized (important in Jupyter)\n",
    "ray.shutdown()  # Clean up any previous Ray state\n",
    "if not ray.is_initialized():\n",
    "    ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40f9860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the Ray Tune with Optuna run\n",
    "TRAINABLE = XGBTrainable\n",
    "STUDY_NAME = \"XGB_Optimization\"\n",
    "MAX_TRAIN_ITERS_PER_TRIAL = 20\n",
    "METRIC = \"roc_auc\"\n",
    "MODE = \"max\"\n",
    "N_TRIALS = 20\n",
    "RESOURCES = {\"cpu\": 1, \"gpu\": 0}  # Adjust based on environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2d975351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-06-01 10:16:52</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:38.59        </td></tr>\n",
       "<tr><td>Memory:      </td><td>12.1/18.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=16<br>Bracket: Iter 64.000: None | Iter 16.000: 0.7088974625368523 | Iter 4.000: 0.7039996395046767 | Iter 1.000: 0.7005577617483603<br>Logical resource usage: 1.0/11 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  colsample_bytree</th><th style=\"text-align: right;\">   gamma</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  n_estimators</th><th style=\"text-align: right;\">  reg_alpha</th><th style=\"text-align: right;\">  reg_lambda</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  f1_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBTrainable_e03e93c6</td><td>TERMINATED</td><td>127.0.0.1:5274</td><td style=\"text-align: right;\">          0.529042</td><td style=\"text-align: right;\">0.780093</td><td style=\"text-align: right;\">    0.202185   </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">           6.38793</td><td style=\"text-align: right;\">            44</td><td style=\"text-align: right;\">0.624576   </td><td style=\"text-align: right;\"> 0.0025706  </td><td style=\"text-align: right;\">   0.577997</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">       13.4111  </td><td style=\"text-align: right;\">0.577778</td><td style=\"text-align: right;\">  0.84501 </td><td style=\"text-align: right;\">  0.422222</td></tr>\n",
       "<tr><td>XGBTrainable_0079008d</td><td>TERMINATED</td><td>127.0.0.1:5277</td><td style=\"text-align: right;\">          0.591702</td><td style=\"text-align: right;\">1.0617  </td><td style=\"text-align: right;\">    0.000117917</td><td style=\"text-align: right;\">         12</td><td style=\"text-align: right;\">           8.49198</td><td style=\"text-align: right;\">            74</td><td style=\"text-align: right;\">5.47243e-06</td><td style=\"text-align: right;\"> 0.000528212</td><td style=\"text-align: right;\">   0.590912</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">       27.4381  </td><td style=\"text-align: right;\">0.648069</td><td style=\"text-align: right;\">  0.781929</td><td style=\"text-align: right;\">  0.351931</td></tr>\n",
       "<tr><td>XGBTrainable_ab7fbd58</td><td>TERMINATED</td><td>127.0.0.1:5278</td><td style=\"text-align: right;\">          0.728035</td><td style=\"text-align: right;\">1.46072 </td><td style=\"text-align: right;\">    0.00102953 </td><td style=\"text-align: right;\">          9</td><td style=\"text-align: right;\">           2.25544</td><td style=\"text-align: right;\">            49</td><td style=\"text-align: right;\">0.116569   </td><td style=\"text-align: right;\"> 6.26706e-07</td><td style=\"text-align: right;\">   0.683181</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">       34.8363  </td><td style=\"text-align: right;\">0.625802</td><td style=\"text-align: right;\">  0.858008</td><td style=\"text-align: right;\">  0.374198</td></tr>\n",
       "<tr><td>XGBTrainable_5439ef95</td><td>TERMINATED</td><td>127.0.0.1:5279</td><td style=\"text-align: right;\">          0.974443</td><td style=\"text-align: right;\">0.852621</td><td style=\"text-align: right;\">    0.0114788  </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">           6.4679 </td><td style=\"text-align: right;\">            56</td><td style=\"text-align: right;\">4.90556    </td><td style=\"text-align: right;\"> 0.188615   </td><td style=\"text-align: right;\">   0.532526</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.756704</td><td style=\"text-align: right;\">0.630063</td><td style=\"text-align: right;\">  0.814998</td><td style=\"text-align: right;\">  0.369937</td></tr>\n",
       "<tr><td>XGBTrainable_7034a82f</td><td>TERMINATED</td><td>127.0.0.1:5280</td><td style=\"text-align: right;\">          0.517194</td><td style=\"text-align: right;\">0.610191</td><td style=\"text-align: right;\">    0.000218584</td><td style=\"text-align: right;\">          9</td><td style=\"text-align: right;\">           4.96137</td><td style=\"text-align: right;\">            37</td><td style=\"text-align: right;\">1.52716    </td><td style=\"text-align: right;\"> 2.13314e-06</td><td style=\"text-align: right;\">   0.747588</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.946875</td><td style=\"text-align: right;\">0.640379</td><td style=\"text-align: right;\">  0.779939</td><td style=\"text-align: right;\">  0.359621</td></tr>\n",
       "<tr><td>XGBTrainable_145e1491</td><td>TERMINATED</td><td>127.0.0.1:5282</td><td style=\"text-align: right;\">          0.887566</td><td style=\"text-align: right;\">0.924272</td><td style=\"text-align: right;\">    0.00121299 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">           5.92039</td><td style=\"text-align: right;\">            70</td><td style=\"text-align: right;\">2.85424    </td><td style=\"text-align: right;\"> 1.13096    </td><td style=\"text-align: right;\">   0.984792</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        2.33326 </td><td style=\"text-align: right;\">0.624517</td><td style=\"text-align: right;\">  0.800993</td><td style=\"text-align: right;\">  0.375483</td></tr>\n",
       "<tr><td>XGBTrainable_84cb55d6</td><td>TERMINATED</td><td>127.0.0.1:5283</td><td style=\"text-align: right;\">          0.694339</td><td style=\"text-align: right;\">0.226136</td><td style=\"text-align: right;\">    0.160498   </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">           2.76385</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">2.76784e-06</td><td style=\"text-align: right;\"> 0.2875     </td><td style=\"text-align: right;\">   0.662665</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.792194</td><td style=\"text-align: right;\">0.599364</td><td style=\"text-align: right;\">  0.831038</td><td style=\"text-align: right;\">  0.400636</td></tr>\n",
       "<tr><td>XGBTrainable_d27c8d7a</td><td>TERMINATED</td><td>127.0.0.1:5284</td><td style=\"text-align: right;\">          0.993443</td><td style=\"text-align: right;\">4.01098 </td><td style=\"text-align: right;\">    0.000948076</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">           2.26832</td><td style=\"text-align: right;\">            42</td><td style=\"text-align: right;\">0.0891667  </td><td style=\"text-align: right;\"> 6.14386e-07</td><td style=\"text-align: right;\">   0.537275</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        5.62281 </td><td style=\"text-align: right;\">0.614821</td><td style=\"text-align: right;\">  0.86001 </td><td style=\"text-align: right;\">  0.385179</td></tr>\n",
       "<tr><td>XGBTrainable_e04b5a36</td><td>TERMINATED</td><td>127.0.0.1:5294</td><td style=\"text-align: right;\">          0.679233</td><td style=\"text-align: right;\">3.85635 </td><td style=\"text-align: right;\">    0.0684634  </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">           7.56106</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">1.10363e-07</td><td style=\"text-align: right;\"> 0.586045   </td><td style=\"text-align: right;\">   0.537022</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.327423</td><td style=\"text-align: right;\">0.637121</td><td style=\"text-align: right;\">  0.827016</td><td style=\"text-align: right;\">  0.362879</td></tr>\n",
       "<tr><td>XGBTrainable_8c086730</td><td>TERMINATED</td><td>127.0.0.1:5296</td><td style=\"text-align: right;\">          0.818779</td><td style=\"text-align: right;\">1.62592 </td><td style=\"text-align: right;\">    0.0014144  </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">           3.79884</td><td style=\"text-align: right;\">            66</td><td style=\"text-align: right;\">0.965861   </td><td style=\"text-align: right;\"> 0.000177801</td><td style=\"text-align: right;\">   0.864803</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.859886</td><td style=\"text-align: right;\">0.626032</td><td style=\"text-align: right;\">  0.779025</td><td style=\"text-align: right;\">  0.373968</td></tr>\n",
       "<tr><td>XGBTrainable_7c69f0a2</td><td>TERMINATED</td><td>127.0.0.1:5297</td><td style=\"text-align: right;\">          0.761366</td><td style=\"text-align: right;\">3.85484 </td><td style=\"text-align: right;\">    0.0302022  </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">           6.05149</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">7.04481e-05</td><td style=\"text-align: right;\"> 1.69345e-08</td><td style=\"text-align: right;\">   0.746898</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.621934</td><td style=\"text-align: right;\">0.609118</td><td style=\"text-align: right;\">  0.833022</td><td style=\"text-align: right;\">  0.390882</td></tr>\n",
       "<tr><td>XGBTrainable_94d2021f</td><td>TERMINATED</td><td>127.0.0.1:5299</td><td style=\"text-align: right;\">          0.624646</td><td style=\"text-align: right;\">2.54285 </td><td style=\"text-align: right;\">    0.000128612</td><td style=\"text-align: right;\">          9</td><td style=\"text-align: right;\">           3.8292 </td><td style=\"text-align: right;\">            19</td><td style=\"text-align: right;\">4.93681e-05</td><td style=\"text-align: right;\"> 0.06309    </td><td style=\"text-align: right;\">   0.953783</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">       13.1359  </td><td style=\"text-align: right;\">0.802988</td><td style=\"text-align: right;\">  0.621753</td><td style=\"text-align: right;\">  0.197012</td></tr>\n",
       "<tr><td>XGBTrainable_6e900d1a</td><td>TERMINATED</td><td>127.0.0.1:5300</td><td style=\"text-align: right;\">          0.816702</td><td style=\"text-align: right;\">4.64849 </td><td style=\"text-align: right;\">    0.000185212</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">           2.45099</td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">0.69686    </td><td style=\"text-align: right;\"> 0.171021   </td><td style=\"text-align: right;\">   0.90406 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.8285  </td><td style=\"text-align: right;\">0.658063</td><td style=\"text-align: right;\">  0.691851</td><td style=\"text-align: right;\">  0.341937</td></tr>\n",
       "<tr><td>XGBTrainable_b466e2b6</td><td>TERMINATED</td><td>127.0.0.1:5301</td><td style=\"text-align: right;\">          0.555026</td><td style=\"text-align: right;\">4.48046 </td><td style=\"text-align: right;\">    0.126922   </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">           8.26696</td><td style=\"text-align: right;\">            26</td><td style=\"text-align: right;\">1.12568e-06</td><td style=\"text-align: right;\"> 6.98184e-05</td><td style=\"text-align: right;\">   0.659002</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">       11.3207  </td><td style=\"text-align: right;\">0.579724</td><td style=\"text-align: right;\">  0.843041</td><td style=\"text-align: right;\">  0.420276</td></tr>\n",
       "<tr><td>XGBTrainable_615885b3</td><td>TERMINATED</td><td>127.0.0.1:5304</td><td style=\"text-align: right;\">          0.507563</td><td style=\"text-align: right;\">2.51266 </td><td style=\"text-align: right;\">    0.000104919</td><td style=\"text-align: right;\">         12</td><td style=\"text-align: right;\">           9.39061</td><td style=\"text-align: right;\">            96</td><td style=\"text-align: right;\">0.00413763 </td><td style=\"text-align: right;\"> 1.03076e-05</td><td style=\"text-align: right;\">   0.770472</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.9639  </td><td style=\"text-align: right;\">0.654942</td><td style=\"text-align: right;\">  0.784953</td><td style=\"text-align: right;\">  0.345058</td></tr>\n",
       "<tr><td>XGBTrainable_fcb810d8</td><td>TERMINATED</td><td>127.0.0.1:5311</td><td style=\"text-align: right;\">          0.510002</td><td style=\"text-align: right;\">2.43566 </td><td style=\"text-align: right;\">    0.00012433 </td><td style=\"text-align: right;\">         12</td><td style=\"text-align: right;\">           9.24074</td><td style=\"text-align: right;\">            97</td><td style=\"text-align: right;\">0.00291513 </td><td style=\"text-align: right;\"> 8.81769e-06</td><td style=\"text-align: right;\">   0.760179</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        8.21004 </td><td style=\"text-align: right;\">0.63011 </td><td style=\"text-align: right;\">  0.797957</td><td style=\"text-align: right;\">  0.36989 </td></tr>\n",
       "<tr><td>XGBTrainable_468e70a2</td><td>TERMINATED</td><td>127.0.0.1:5312</td><td style=\"text-align: right;\">          0.524581</td><td style=\"text-align: right;\">2.34353 </td><td style=\"text-align: right;\">    0.000105469</td><td style=\"text-align: right;\">         12</td><td style=\"text-align: right;\">           9.94606</td><td style=\"text-align: right;\">            90</td><td style=\"text-align: right;\">0.00398664 </td><td style=\"text-align: right;\"> 1.27211e-05</td><td style=\"text-align: right;\">   0.772252</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        2.12746 </td><td style=\"text-align: right;\">0.645401</td><td style=\"text-align: right;\">  0.780946</td><td style=\"text-align: right;\">  0.354599</td></tr>\n",
       "<tr><td>XGBTrainable_81d34a8c</td><td>TERMINATED</td><td>127.0.0.1:5314</td><td style=\"text-align: right;\">          0.620777</td><td style=\"text-align: right;\">2.65111 </td><td style=\"text-align: right;\">    0.000704665</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">           1.02942</td><td style=\"text-align: right;\">            41</td><td style=\"text-align: right;\">0.00669822 </td><td style=\"text-align: right;\"> 2.72758e-07</td><td style=\"text-align: right;\">   0.636253</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.54028 </td><td style=\"text-align: right;\">0.586005</td><td style=\"text-align: right;\">  0.856006</td><td style=\"text-align: right;\">  0.413995</td></tr>\n",
       "<tr><td>XGBTrainable_2f641a4a</td><td>TERMINATED</td><td>127.0.0.1:5315</td><td style=\"text-align: right;\">          0.98378 </td><td style=\"text-align: right;\">2.55212 </td><td style=\"text-align: right;\">    0.000553152</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">           1.02672</td><td style=\"text-align: right;\">            39</td><td style=\"text-align: right;\">0.0159368  </td><td style=\"text-align: right;\"> 3.05395e-07</td><td style=\"text-align: right;\">   0.653734</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        6.19787 </td><td style=\"text-align: right;\">0.624549</td><td style=\"text-align: right;\">  0.854004</td><td style=\"text-align: right;\">  0.375451</td></tr>\n",
       "<tr><td>XGBTrainable_2b45de47</td><td>TERMINATED</td><td>127.0.0.1:5316</td><td style=\"text-align: right;\">          0.989713</td><td style=\"text-align: right;\">3.31447 </td><td style=\"text-align: right;\">    0.000469728</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">           4.25047</td><td style=\"text-align: right;\">            38</td><td style=\"text-align: right;\">0.070721   </td><td style=\"text-align: right;\"> 3.95049e-07</td><td style=\"text-align: right;\">   0.68339 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        4.82808 </td><td style=\"text-align: right;\">0.616797</td><td style=\"text-align: right;\">  0.837991</td><td style=\"text-align: right;\">  0.383203</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 10:16:52,756\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/milosz/ray_results/XGB_Optimization' in 0.0108s.\n",
      "2025-06-01 10:16:52,760\tINFO tune.py:1041 -- Total run time: 38.61 seconds (38.58 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'n_estimators': 49, 'learning_rate': 0.001029530064265006, 'max_depth': 9, 'min_child_weight': 2.2554447458683766, 'gamma': 1.4607232426760908, 'subsample': 0.6831809216468459, 'colsample_bytree': 0.728034992108518, 'reg_alpha': 0.11656915613247415, 'reg_lambda': 6.267062696005991e-07}\n",
      "Best roc_auc found: 0.7095\n"
     ]
    }
   ],
   "source": [
    "# Define the RunConfig\n",
    "# It is important to define stop condition!\n",
    "run_config = RunConfig(\n",
    "    callbacks=[\n",
    "        # WandbLoggerCallback(project=study_name),\n",
    "    ],\n",
    "    stop={\"training_iteration\": MAX_TRAIN_ITERS_PER_TRIAL},\n",
    "    checkpoint_config=CheckpointConfig(checkpoint_at_end=True),\n",
    "    name=STUDY_NAME,\n",
    ")\n",
    "\n",
    "# Define the Optuna search algorithm\n",
    "optuna_search = OptunaSearch(\n",
    "    define_search_space,\n",
    "    metric=METRIC,\n",
    "    mode=MODE,\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "    study_name=STUDY_NAME,\n",
    ")\n",
    "\n",
    "# Create the Tuner object\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(TRAINABLE, resources=RESOURCES),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        scheduler=ASHAScheduler(metric=METRIC, mode=MODE),\n",
    "        num_samples=N_TRIALS,\n",
    "        search_alg=optuna_search,\n",
    "    ),\n",
    "    run_config=run_config,\n",
    ")\n",
    "\n",
    "# Start the hyperparameter tuning process\n",
    "results = tuner.fit()\n",
    "\n",
    "best_result = results.get_best_result(metric=METRIC, mode=MODE)\n",
    "best_params = best_result.config\n",
    "print(f\"Best hyperparameters found: {best_params}\")\n",
    "best_metric = best_result.metrics[METRIC]\n",
    "print(f\"Best {METRIC} found: {best_metric:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b986e127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier Metrics:\n",
      "    accuracy: 0.1350\n",
      "    f1_score: 0.2379\n",
      "    precision: 0.1350\n",
      "    recall: 1.0000\n",
      "    roc_auc: 0.6690\n",
      "    balanced_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "xgb_best_params = {**best_params, **XGBTrainable.fixed_params}\n",
    "xgb_clf = XGBClassifier(**xgb_best_params)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = xgb_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "xgb_clf_metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"f1_score\": f1_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\": recall_score(y_test, y_pred),\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_pred_proba),\n",
    "    \"balanced_accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "}\n",
    "print(\"XGB Classifier Metrics:\")\n",
    "for metric, value in xgb_clf_metrics.items():\n",
    "    print(f\"    {metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "47856567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, define the Trainable class for your model\n",
    "# You need to implement:\n",
    "#  - setup (with dataset and model initialization),\n",
    "#  - step (for training and evaluation),\n",
    "#  - save_checkpoint (to save the model),\n",
    "#  - load_checkpoint (to load the model from a checkpoint).\n",
    "class CatBoostTrainable(tune.Trainable):\n",
    "    SHOULD_SET_EVAL_SET = True  # CatBoostoost supports eval_set\n",
    "\n",
    "    fixed_params = {\n",
    "        \"scale_pos_weight\": scale_pos_weight,\n",
    "        # \"eval_metric\": \"AUC\",\n",
    "        \"early_stopping_rounds\": 5,\n",
    "        \"random_state\": SEED,\n",
    "        # \"task_type\": \"GPU\",\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "\n",
    "    def setup_dataset(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def setup_skf(self, n_splits, seed):\n",
    "        self.skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    def setup(self, config):\n",
    "        self.setup_dataset(X_hyperparameter_tuning, y_hyperparameter_tuning)\n",
    "        self.setup_skf(N_SPLITS, CatBoostTrainable.fixed_params[\"random_state\"])\n",
    "\n",
    "        self.model = CatBoostClassifier(**config, **CatBoostTrainable.fixed_params)\n",
    "\n",
    "    def calculate_metrics(self, y_true, y_pred_proba):\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "        return {\n",
    "            \"loss\": 1 - f1_score(y_true, y_pred),\n",
    "            \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"f1_score\": f1_score(y_true, y_pred),\n",
    "            \"precision\": precision_score(y_true, y_pred),\n",
    "            \"recall\": recall_score(y_true, y_pred),\n",
    "            \"roc_auc\": roc_auc_score(y_true, y_pred_proba),\n",
    "            \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        }\n",
    "\n",
    "    def step(self):\n",
    "        cv_scores = []\n",
    "        for train_idx, valid_idx in self.skf.split(self.X, self.y):\n",
    "            X_train_fold, X_valid_fold = self.X[train_idx], self.X[valid_idx]\n",
    "            y_train_fold, y_valid_fold = self.y[train_idx], self.y[valid_idx]\n",
    "\n",
    "            self.model.fit(\n",
    "                X_train_fold,\n",
    "                y_train_fold,\n",
    "                **(\n",
    "                    {\"eval_set\": [(X_valid_fold, y_valid_fold)]}\n",
    "                    if CatBoostTrainable.SHOULD_SET_EVAL_SET\n",
    "                    else {}\n",
    "                ),\n",
    "            )\n",
    "            y_pred_proba = self.model.predict_proba(X_valid_fold)[:, 1]\n",
    "\n",
    "            cv_scores.append(self.calculate_metrics(y_valid_fold, y_pred_proba))\n",
    "\n",
    "        return {\n",
    "            \"loss\": np.mean([score[\"loss\"] for score in cv_scores]),\n",
    "            \"accuracy\": np.mean([score[\"accuracy\"] for score in cv_scores]),\n",
    "            \"f1_score\": np.mean([score[\"f1_score\"] for score in cv_scores]),\n",
    "            \"precision\": np.mean([score[\"precision\"] for score in cv_scores]),\n",
    "            \"recall\": np.mean([score[\"recall\"] for score in cv_scores]),\n",
    "            \"roc_auc\": np.mean([score[\"roc_auc\"] for score in cv_scores]),\n",
    "            \"balanced_accuracy\": np.mean(\n",
    "                [score[\"balanced_accuracy\"] for score in cv_scores]\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir):\n",
    "        checkpoint_path = f\"{checkpoint_dir}/model.pkl\"\n",
    "        with open(checkpoint_path, \"wb\") as f:\n",
    "            pickle.dump(self.model, f)\n",
    "        return {\"path\": checkpoint_path}\n",
    "\n",
    "    def load_checkpoint(self, checkpoint):\n",
    "        if not isinstance(checkpoint, dict):\n",
    "            raise ValueError(\n",
    "                \"Checkpoint must be a dictionary containing the path to the model.\"\n",
    "            )\n",
    "        with open(checkpoint[\"path\"], \"rb\") as f:\n",
    "            self.model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7ec8c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, you need to define the search space for hyperparameters.\n",
    "# It is a function that takes an `optuna.Trial` object and suggests hyperparameters.\n",
    "def define_search_space(trial: optuna.Trial):\n",
    "    trial.suggest_int(\"iterations\", 10, 200)\n",
    "    trial.suggest_float(\"learning_rate\", 1e-4, 0.3, log=True)\n",
    "    trial.suggest_int(\"depth\", 4, 10)\n",
    "    trial.suggest_float(\"l2_leaf_reg\", 1.0, 10.0)\n",
    "    trial.suggest_float(\"bagging_temperature\", 0.0, 1.0)\n",
    "    trial.suggest_float(\"random_strength\", 0.0, 1.0)\n",
    "    trial.suggest_int(\"border_count\", 32, 127)\n",
    "\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7ea42b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 10:28:03,499\tINFO worker.py:1888 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "# Ensure Ray is initialized (important in Jupyter)\n",
    "ray.shutdown()  # Clean up any previous Ray state\n",
    "if not ray.is_initialized():\n",
    "    ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c553eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the Ray Tune with Optuna run\n",
    "TRAINABLE = CatBoostTrainable\n",
    "STUDY_NAME = \"CatBoost_Optimization\"\n",
    "MAX_TRAIN_ITERS_PER_TRIAL = 20\n",
    "METRIC = \"roc_auc\"\n",
    "MODE = \"max\"\n",
    "N_TRIALS = 20\n",
    "RESOURCES = {\"cpu\": 1, \"gpu\": 0}  # Adjust based on environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f386bad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-06-01 10:33:53</td></tr>\n",
       "<tr><td>Running for: </td><td>00:05:11.73        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.9/18.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=16<br>Bracket: Iter 64.000: 0.70685757605937 | Iter 16.000: 0.7063691539908843 | Iter 4.000: 0.7060272484122931 | Iter 1.000: 0.7011528137902943<br>Logical resource usage: 1.0/11 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  bagging_temperature</th><th style=\"text-align: right;\">  border_count</th><th style=\"text-align: right;\">  depth</th><th style=\"text-align: right;\">  iterations</th><th style=\"text-align: right;\">  l2_leaf_reg</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  random_strength</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  f1_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>CatBoostTrainable_4914ec1d</td><td>TERMINATED</td><td>127.0.0.1:5809</td><td style=\"text-align: right;\">            0.156019 </td><td style=\"text-align: right;\">            37</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">          81</td><td style=\"text-align: right;\">      6.38793</td><td style=\"text-align: right;\">    0.202185   </td><td style=\"text-align: right;\">        0.155995 </td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">       138.14   </td><td style=\"text-align: right;\">0.660664</td><td style=\"text-align: right;\">  0.761027</td><td style=\"text-align: right;\">  0.339336</td></tr>\n",
       "<tr><td>CatBoostTrainable_a5e0ed44</td><td>TERMINATED</td><td>127.0.0.1:5810</td><td style=\"text-align: right;\">            0.96991  </td><td style=\"text-align: right;\">            52</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">         175</td><td style=\"text-align: right;\">      1.18526</td><td style=\"text-align: right;\">    0.0123069  </td><td style=\"text-align: right;\">        0.832443 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">       116.327  </td><td style=\"text-align: right;\">0.604756</td><td style=\"text-align: right;\">  0.845013</td><td style=\"text-align: right;\">  0.395244</td></tr>\n",
       "<tr><td>CatBoostTrainable_0d8384ad</td><td>TERMINATED</td><td>127.0.0.1:5812</td><td style=\"text-align: right;\">            0.431945 </td><td style=\"text-align: right;\">            90</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">          44</td><td style=\"text-align: right;\">      5.72281</td><td style=\"text-align: right;\">    0.00043423 </td><td style=\"text-align: right;\">        0.291229 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.15041</td><td style=\"text-align: right;\">0.650924</td><td style=\"text-align: right;\">  0.778027</td><td style=\"text-align: right;\">  0.349076</td></tr>\n",
       "<tr><td>CatBoostTrainable_bdbaa678</td><td>TERMINATED</td><td>127.0.0.1:5814</td><td style=\"text-align: right;\">            0.785176 </td><td style=\"text-align: right;\">            81</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">          36</td><td style=\"text-align: right;\">      5.10463</td><td style=\"text-align: right;\">    0.0010371  </td><td style=\"text-align: right;\">        0.199674 </td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">       223.506  </td><td style=\"text-align: right;\">0.638889</td><td style=\"text-align: right;\">  0.797031</td><td style=\"text-align: right;\">  0.361111</td></tr>\n",
       "<tr><td>CatBoostTrainable_e984d147</td><td>TERMINATED</td><td>127.0.0.1:5815</td><td style=\"text-align: right;\">            0.0650516</td><td style=\"text-align: right;\">           124</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">         123</td><td style=\"text-align: right;\">      2.53472</td><td style=\"text-align: right;\">    0.000145049</td><td style=\"text-align: right;\">        0.948886 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">       259.765  </td><td style=\"text-align: right;\">0.62946 </td><td style=\"text-align: right;\">  0.834023</td><td style=\"text-align: right;\">  0.37054 </td></tr>\n",
       "<tr><td>CatBoostTrainable_cb2d8fb4</td><td>TERMINATED</td><td>127.0.0.1:5816</td><td style=\"text-align: right;\">            0.440152 </td><td style=\"text-align: right;\">            79</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">         164</td><td style=\"text-align: right;\">      7.1581 </td><td style=\"text-align: right;\">    0.00114599 </td><td style=\"text-align: right;\">        0.122038 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.71272</td><td style=\"text-align: right;\">0.653749</td><td style=\"text-align: right;\">  0.772009</td><td style=\"text-align: right;\">  0.346251</td></tr>\n",
       "<tr><td>CatBoostTrainable_9b952fc2</td><td>TERMINATED</td><td>127.0.0.1:5818</td><td style=\"text-align: right;\">            0.311711 </td><td style=\"text-align: right;\">            84</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      6.9627 </td><td style=\"text-align: right;\">    0.14515    </td><td style=\"text-align: right;\">        0.520068 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       176.963  </td><td style=\"text-align: right;\">0.665172</td><td style=\"text-align: right;\">  0.747007</td><td style=\"text-align: right;\">  0.334828</td></tr>\n",
       "<tr><td>CatBoostTrainable_b272b23c</td><td>TERMINATED</td><td>127.0.0.1:5824</td><td style=\"text-align: right;\">            0.894827 </td><td style=\"text-align: right;\">           120</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">          45</td><td style=\"text-align: right;\">      9.45549</td><td style=\"text-align: right;\">    0.23516    </td><td style=\"text-align: right;\">        0.5979   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.80578</td><td style=\"text-align: right;\">0.693424</td><td style=\"text-align: right;\">  0.702028</td><td style=\"text-align: right;\">  0.306576</td></tr>\n",
       "<tr><td>CatBoostTrainable_7f948cd2</td><td>TERMINATED</td><td>127.0.0.1:5830</td><td style=\"text-align: right;\">            0.388677 </td><td style=\"text-align: right;\">           111</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">          26</td><td style=\"text-align: right;\">      3.92797</td><td style=\"text-align: right;\">    0.000480238</td><td style=\"text-align: right;\">        0.271349 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.80957</td><td style=\"text-align: right;\">0.661907</td><td style=\"text-align: right;\">  0.758039</td><td style=\"text-align: right;\">  0.338093</td></tr>\n",
       "<tr><td>CatBoostTrainable_3ce3aa6a</td><td>TERMINATED</td><td>127.0.0.1:5831</td><td style=\"text-align: right;\">            0.802197 </td><td style=\"text-align: right;\">           126</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">          78</td><td style=\"text-align: right;\">      2.26832</td><td style=\"text-align: right;\">    0.000948076</td><td style=\"text-align: right;\">        0.0745506</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        12.0917 </td><td style=\"text-align: right;\">0.633692</td><td style=\"text-align: right;\">  0.805021</td><td style=\"text-align: right;\">  0.366308</td></tr>\n",
       "<tr><td>CatBoostTrainable_865dd9ec</td><td>TERMINATED</td><td>127.0.0.1:5832</td><td style=\"text-align: right;\">            0.706857 </td><td style=\"text-align: right;\">           106</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">         157</td><td style=\"text-align: right;\">      8.33915</td><td style=\"text-align: right;\">    0.000490861</td><td style=\"text-align: right;\">        0.729007 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.6566 </td><td style=\"text-align: right;\">0.648334</td><td style=\"text-align: right;\">  0.797019</td><td style=\"text-align: right;\">  0.351666</td></tr>\n",
       "<tr><td>CatBoostTrainable_dd654752</td><td>TERMINATED</td><td>127.0.0.1:5835</td><td style=\"text-align: right;\">            0.623298 </td><td style=\"text-align: right;\">            38</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">      8.76793</td><td style=\"text-align: right;\">    0.00176372 </td><td style=\"text-align: right;\">        0.330898 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.77938</td><td style=\"text-align: right;\">0.67706 </td><td style=\"text-align: right;\">  0.745044</td><td style=\"text-align: right;\">  0.32294 </td></tr>\n",
       "<tr><td>CatBoostTrainable_6e6994ad</td><td>TERMINATED</td><td>127.0.0.1:5847</td><td style=\"text-align: right;\">            0.887213 </td><td style=\"text-align: right;\">            43</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">          69</td><td style=\"text-align: right;\">      6.73802</td><td style=\"text-align: right;\">    0.00135114 </td><td style=\"text-align: right;\">        0.472215 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        59.2997 </td><td style=\"text-align: right;\">0.611596</td><td style=\"text-align: right;\">  0.815019</td><td style=\"text-align: right;\">  0.388404</td></tr>\n",
       "<tr><td>CatBoostTrainable_2b0eb7cb</td><td>TERMINATED</td><td>127.0.0.1:5856</td><td style=\"text-align: right;\">            0.493796 </td><td style=\"text-align: right;\">            73</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">         146</td><td style=\"text-align: right;\">      7.9387 </td><td style=\"text-align: right;\">    0.0441918  </td><td style=\"text-align: right;\">        0.522733 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       283.88   </td><td style=\"text-align: right;\">0.637601</td><td style=\"text-align: right;\">  0.780997</td><td style=\"text-align: right;\">  0.362399</td></tr>\n",
       "<tr><td>CatBoostTrainable_4445abbe</td><td>TERMINATED</td><td>127.0.0.1:5862</td><td style=\"text-align: right;\">            0.314356 </td><td style=\"text-align: right;\">           119</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">          14</td><td style=\"text-align: right;\">      6.72769</td><td style=\"text-align: right;\">    0.00023722 </td><td style=\"text-align: right;\">        0.508571 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.58657</td><td style=\"text-align: right;\">0.653016</td><td style=\"text-align: right;\">  0.783008</td><td style=\"text-align: right;\">  0.346984</td></tr>\n",
       "<tr><td>CatBoostTrainable_8907930c</td><td>TERMINATED</td><td>127.0.0.1:5864</td><td style=\"text-align: right;\">            0.0769799</td><td style=\"text-align: right;\">            47</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">          57</td><td style=\"text-align: right;\">      3.05918</td><td style=\"text-align: right;\">    0.00267271 </td><td style=\"text-align: right;\">        0.289751 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        14.8696 </td><td style=\"text-align: right;\">0.608362</td><td style=\"text-align: right;\">  0.830019</td><td style=\"text-align: right;\">  0.391638</td></tr>\n",
       "<tr><td>CatBoostTrainable_42142fff</td><td>TERMINATED</td><td>127.0.0.1:5865</td><td style=\"text-align: right;\">            0.803672 </td><td style=\"text-align: right;\">           117</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">         187</td><td style=\"text-align: right;\">      8.84315</td><td style=\"text-align: right;\">    0.0645554  </td><td style=\"text-align: right;\">        0.18657  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.0339 </td><td style=\"text-align: right;\">0.631919</td><td style=\"text-align: right;\">  0.791996</td><td style=\"text-align: right;\">  0.368081</td></tr>\n",
       "<tr><td>CatBoostTrainable_b140be99</td><td>TERMINATED</td><td>127.0.0.1:5882</td><td style=\"text-align: right;\">            0.110052 </td><td style=\"text-align: right;\">            73</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">         113</td><td style=\"text-align: right;\">      3.86203</td><td style=\"text-align: right;\">    0.0642048  </td><td style=\"text-align: right;\">        0.227935 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       275.694  </td><td style=\"text-align: right;\">0.631522</td><td style=\"text-align: right;\">  0.80301 </td><td style=\"text-align: right;\">  0.368478</td></tr>\n",
       "<tr><td>CatBoostTrainable_d52befd5</td><td>TERMINATED</td><td>127.0.0.1:5888</td><td style=\"text-align: right;\">            0.417411 </td><td style=\"text-align: right;\">            43</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">         166</td><td style=\"text-align: right;\">      5.59673</td><td style=\"text-align: right;\">    0.0983704  </td><td style=\"text-align: right;\">        0.222108 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.98711</td><td style=\"text-align: right;\">0.668752</td><td style=\"text-align: right;\">  0.753025</td><td style=\"text-align: right;\">  0.331248</td></tr>\n",
       "<tr><td>CatBoostTrainable_41d916c8</td><td>TERMINATED</td><td>127.0.0.1:5892</td><td style=\"text-align: right;\">            0.703019 </td><td style=\"text-align: right;\">           125</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">          74</td><td style=\"text-align: right;\">      5.66912</td><td style=\"text-align: right;\">    0.189938   </td><td style=\"text-align: right;\">        0.36363  </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       173.074  </td><td style=\"text-align: right;\">0.627044</td><td style=\"text-align: right;\">  0.759988</td><td style=\"text-align: right;\">  0.372956</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 10:33:53,389\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/milosz/ray_results/CatBoost_Optimization' in 0.0081s.\n",
      "2025-06-01 10:33:53,393\tINFO tune.py:1041 -- Total run time: 311.77 seconds (311.72 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'iterations': 74, 'learning_rate': 0.1899377866077047, 'depth': 6, 'l2_leaf_reg': 5.669115595690295, 'bagging_temperature': 0.7030189588951778, 'random_strength': 0.363629602379294, 'border_count': 125}\n",
      "Best roc_auc found: 0.7153\n"
     ]
    }
   ],
   "source": [
    "# Define the RunConfig\n",
    "# It is important to define stop condition!\n",
    "run_config = RunConfig(\n",
    "    callbacks=[\n",
    "        # WandbLoggerCallback(project=study_name),\n",
    "    ],\n",
    "    stop={\"training_iteration\": MAX_TRAIN_ITERS_PER_TRIAL},\n",
    "    checkpoint_config=CheckpointConfig(checkpoint_at_end=True),\n",
    "    name=STUDY_NAME,\n",
    ")\n",
    "\n",
    "# Define the Optuna search algorithm\n",
    "optuna_search = OptunaSearch(\n",
    "    define_search_space,\n",
    "    metric=METRIC,\n",
    "    mode=MODE,\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "    study_name=STUDY_NAME,\n",
    ")\n",
    "\n",
    "# Create the Tuner object\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(TRAINABLE, resources=RESOURCES),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        scheduler=ASHAScheduler(metric=METRIC, mode=MODE),\n",
    "        num_samples=N_TRIALS,\n",
    "        search_alg=optuna_search,\n",
    "    ),\n",
    "    run_config=run_config,\n",
    ")\n",
    "\n",
    "# Start the hyperparameter tuning process\n",
    "results = tuner.fit()\n",
    "\n",
    "best_result = results.get_best_result(metric=METRIC, mode=MODE)\n",
    "best_params = best_result.config\n",
    "print(f\"Best hyperparameters found: {best_params}\")\n",
    "best_metric = best_result.metrics[METRIC]\n",
    "print(f\"Best {METRIC} found: {best_metric:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f04611e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Classifier Metrics:\n",
      "    accuracy: 0.8500\n",
      "    f1_score: 0.3478\n",
      "    precision: 0.4211\n",
      "    recall: 0.2963\n",
      "    roc_auc: 0.6776\n",
      "    balanced_accuracy: 0.6164\n"
     ]
    }
   ],
   "source": [
    "catb_best_params = {**best_params, **CatBoostTrainable.fixed_params}\n",
    "catb_clf = CatBoostClassifier(**catb_best_params)\n",
    "catb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = catb_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "catb_clf_metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"f1_score\": f1_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\": recall_score(y_test, y_pred),\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_pred_proba),\n",
    "    \"balanced_accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "}\n",
    "print(\"CatBoost Classifier Metrics:\")\n",
    "for metric, value in catb_clf_metrics.items():\n",
    "    print(f\"    {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8ffff1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              accuracy  f1_score  precision    recall   roc_auc  \\\n",
      "LightGBM         0.865  0.000000   0.000000  0.000000  0.661100   \n",
      "RandomForest     0.885  0.342857   0.750000  0.222222  0.624492   \n",
      "XGBoost          0.135  0.237885   0.135000  1.000000  0.669022   \n",
      "CatBoost         0.850  0.347826   0.421053  0.296296  0.677585   \n",
      "\n",
      "              balanced_accuracy  \n",
      "LightGBM               0.500000  \n",
      "RandomForest           0.605331  \n",
      "XGBoost                0.500000  \n",
      "CatBoost               0.616356  \n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    \"LightGBM\": lgbm_clf_metrics,\n",
    "    \"RandomForest\": rf_clf_metrics,\n",
    "    \"XGBoost\": xgb_clf_metrics,\n",
    "    \"CatBoost\": catb_clf_metrics,\n",
    "}).T\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "00359453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = [\n",
    "    \"accuracy\",\n",
    "    \"f1_score\",\n",
    "    \"precision\",\n",
    "    \"recall\",\n",
    "    \"roc_auc\",\n",
    "    \"balanced_accuracy\",\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "df_results[metrics].plot(\n",
    "    kind=\"bar\", ax=ax, colormap=\"Set2\", width=0.8, edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "ax.set_title(\"All Classifiers Metrics Comparison\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend(loc=\"upper right\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
